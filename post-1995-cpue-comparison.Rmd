---
title: "Post 1995 CPUE GLM comparison"
author: "Sean Anderson"
date: '2018-08-01'
output: html_document
---

```{r, knitr-opts, cache=FALSE, echo=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.path = "cpue-comp-figs/",
  cache.path = "cpue-comp-cache/",
  fig.asp = 0.618,
  echo = TRUE,
  autodep = TRUE,
  cache = TRUE,
  cache.comments = FALSE,
  fig.align = "center"
)
```

```{r packages, cache=FALSE}
library("dplyr")
library("ggplot2")
library("gfplot")
ggplot2::theme_set(gfplot::theme_pbs())
```

Extract the data from our databases:

```{r load-data}
if (!file.exists(here::here("data/cpue-index-dat.rds"))) {
  dcpue <- gfplot::get_cpue_index(gear = "bottom trawl", min_cpue_year = 1996)
  readr::write_rds(d, here::here("data/cpue-index-dat.rds"))
} else {
  dcpue <- readr::read_rds(here::here("data/cpue-index-dat.rds"))
}
```

Switch to a fishing year that starts April 1. I will add this option to the package shortly.

```{r}
alt_year_start_date <- "04-01" # fishing year
dcpue$year <- lubridate::year(dcpue$best_date)
dcpue <- dplyr::mutate(dcpue, .year_start_date =
    lubridate::ymd_hms(paste0(year, "-", alt_year_start_date, " 00:00:00")))
dcpue <- dplyr::mutate(dcpue, .time_diff = best_date - .year_start_date)
dcpue <- dplyr::mutate(dcpue, alt_year = ifelse(.time_diff > 0, year, year - 1L))
dcpue <- dplyr::select(dcpue, -.time_diff, -.year_start_date)
# make 'year' column mean 'fishing year'
dcpue$year <- NULL
dcpue$year <- dcpue$alt_year
dcpue$alt_year <- NULL
```

Define our fleet:

```{r define-fleet}
dfleet <- gfplot::tidy_cpue_index(dcpue, species_common = "pacific cod",
  year_range = c(1996, 2017), lat_range = c(48, Inf),
  min_positive_tows = 600,
  min_positive_trips = 5,
  min_yrs_with_trips = 5,
  area_grep_pattern = "^5[ABCD]+",
  lat_bin_quantiles = c(0, 1),
  depth_bin_quantiles = c(0, 1),
  gear = "BOTTOM TRAWL",
  lat_band_width = 0.1,
  depth_band_width = 25
)
```

Match the filtering of Paul:

```{r}
dfleet <- filter(dfleet, hours_fished <= 5, best_depth >= 25,
  best_depth <= 325)
```

Look at the characteristics of our fleet data set:

```{r}
nrow(dfleet)
sum(dfleet$pos_catch)
length(unique(dfleet$vessel))
sum(dfleet$spp_catch) / 1000
hist(dfleet$best_depth)
```

Match the depth bins of Paul and change the base factor levels to specific levels (roughly the most common levels):

```{r}
# depth_bands <- c(seq(25, 150, 25), 200, 325)
depth_bands <- seq(25, 325, 25)
dfleet <- dfleet %>%
  mutate(depth_bin = gfplot:::factor_bin_clean(best_depth, depth_bands))
dfleet$depth_bin <- relevel(dfleet$depth_bin, ref = "075")
dfleet$month <- relevel(dfleet$month, ref = "05")
```

Remove a small number of localities with almost no positive fishing events so the models can be estimated well:

```{r}
small_localities <- group_by(dfleet, locality) %>%
  summarize(pos_catch_tot = sum(pos_catch)) %>%
  filter(pos_catch_tot < 25) %>%
  arrange(-pos_catch_tot) %>%
  ungroup()

small_localities

# too few positive events so drop:
dfleet <- filter(dfleet, !locality %in% small_localities$locality)
```

Match PJS models. Note that our models are slightly different in that I am modeling CPUE as the response whereas Paul is modeling catch as the response with a third order polynomial for effort. My model is effectively treating effort as a predictor with a fixed coefficient of one.

```{r fit-main-model, results='hide', message=FALSE, warning=FALSE}
m1996 <- fit_cpue_index(dfleet,
  formula_binomial = pos_catch ~ year_factor +
  f(locality) + f(depth) + f(latitude),
  formula_lognormal = log(spp_catch/hours_fished) ~ year_factor +
  f(vessel) + f(locality) + f(depth) + f(latitude))
```

Plot the coefficients. These are effects in log-odds space (binomial/'Bin.'/black) or log space (lognormal/ 'Pos.'/blue) compared to the base factor level in each case. The depth base factor level was manually set to 75m above. The other base factor levels were automatically set to the most common levels in the data set.

```{r, fig.asp=1.7}
plot_cpue_index_coefs(m1996)
```

Look at the sensitivity of each predictor by 'jackknifing' each one out one at a time. The dashed great line is the standardized time series. The colored line refers to the version in the panel label.

```{r jackknife, results='hide', message=FALSE, warning=FALSE}
plot_cpue_index_jk(m1996,
  terms = c("f(vessel)", "f(locality)", "f(depth)", "f(latitude)"))
```

So no one variable has a major effect if it is omitted. Of the other variables can largely account for the same variation. Latitude has the largest effect if it is omitted. I imagine that locality and latitude are accounting for similar variation.

A model without standardization for comparison later:

```{r fit-unstandardized-model, results='hide', message=FALSE, warning=FALSE}
m1996_unstd <- fit_cpue_index(dfleet, formula_binomial = pos_catch ~ year_factor,
  formula_lognormal = log(spp_catch/hours_fished) ~ year_factor)
```

Now make a comparison plot. The lognormal timeseries is centered by its geometric mean. The binomial timeseries is plotted in log-odds space and centered on its arithmetic mean.

Note that we cannot compare the 'Combined' model because we are using different methods to combine the binomial and lognormal models. My version is multiplying the probability of a tow catching Pacific Cod by the expected CPUE if Pacific Cod is caught. I'm not sure exactly what Paul's method is here but even if it was the same we wouldn't get the same answer unless we picked the same base factor levels for comparison since it affects the relative contribution of the binomial and lognormal components.

The choice of the most common base levels and multiplicative combination of the binomial (in probability space) and lognormal (in exponentiated, i.e. natural space) models is following, for example:

```
@article{maunder2004,
  title = {Standardizing Catch and Effort Data: A Review of Recent Approaches},
  author = {Maunder, Mark N. and Punt, Andr\'e E.},
  journal = {Fisheries Research},
  year = {2004},
  volume = {70},
  number = {2},
  pages = {141-159}
  series = {Models in Fisheries Research: GLMs, GAMS and GLMMs},
  doi = {10.1016/j.fishres.2004.08.002},
}
```

```{r make-comparison-plot, fig.asp=0.45, cache=FALSE}
m1996_pred_unstd <- m1996_unstd %>%
  predict_cpue_index(center = FALSE) %>%
  mutate(version = "gfplot\nunstandardized") %>%
  mutate(est = ifelse(model == "Binomial", est_link, est)) %>%
  mutate(lwr = ifelse(model == "Binomial", est_link - 1.96 * se_link, lwr)) %>%
  mutate(upr = ifelse(model == "Binomial", est_link + 1.96 * se_link, upr))

m1996_pred <- m1996 %>%
  predict_cpue_index(center = FALSE) %>%
  mutate(version = "gfplot\nstandardized") %>%
  mutate(est = ifelse(model == "Binomial", est_link, est)) %>%
  mutate(lwr = ifelse(model == "Binomial", est_link - 1.96 * se_link, lwr)) %>%
  mutate(upr = ifelse(model == "Binomial", est_link + 1.96 * se_link, upr))

ps_1996 <- read.csv(here::here("data/Paul_Starr_5ABCD_indices.csv"),
  stringsAsFactors = FALSE, strip.white = TRUE)

pal <- c(RColorBrewer::brewer.pal(4, "Dark2"))
pal <- c(pal[1], "grey50", pal[4])
lty <- c(1, 2, 1)

ps_1996 %>%
  rename(year = fyr, Binomial = binomial,
    Lognormal = lognormal, Combined = combined, lwr = lb, upr = ub) %>%
  reshape2::melt(id.vars = c("year", "lwr", "upr")) %>%
  rename(model = variable, est = value) %>%
  mutate(version = "PJS") %>%
  # make '95/96' into '1995' etc.:
  mutate(year = as.numeric(gsub("(^[0-9]+)\\/[0-9]+$", "\\1", year))) %>%
  mutate(year = as.numeric(
    if_else(year > 80,
      paste0("19", sprintf("%02d", year)),
      paste0("20", sprintf("%02d", year))))) %>%
  bind_rows(m1996_pred) %>%
  bind_rows(m1996_pred_unstd) %>%
  group_by(model, version) %>%
  mutate(lwr = ifelse(version == "PJS" & model != "Combined", NA, lwr)) %>%
  mutate(upr = ifelse(version == "PJS" & model != "Combined", NA, upr)) %>%
  mutate(geo_mean = ifelse(model == "Binomial", mean(est), exp(mean(log(est))))) %>%
  mutate(upr = upr/geo_mean, lwr = lwr/geo_mean, est = est/geo_mean) %>%
  ungroup() %>%
  # filter(model != "Combined") %>%
  ggplot(aes(year, est)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = version), alpha = 0.5) +
  geom_line(aes(colour = version, lty = version)) +
  facet_wrap(~model, scales = "free_y") +
  theme_pbs() +
  scale_colour_manual(values = pal) +
  scale_fill_manual(values = pal) +
  scale_linetype_manual(values = lty) +
  ylab("Index divided by mean/geometric mean") + xlab("Year") +
  theme(legend.position = "bottom")
```

The binomial and lognormal components look very similar to each other and similarly different from the unstandardized timeseries. As mentioned above, the combined timeseries are not directly comparable. Given the similarity of the binomial and lognormal timeseries, I imagine if they were combined in the same method the result would look the same. I can't try that here because I only have the scaled version of Paul's binomial and lognormal timeseries.
